{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pyTelegramBotAPI\n",
    "#%pip install python-dotenv\n",
    "#%pip install git+https://github.com/huggingface/transformers.git\n",
    "#%pip install accelerate\n",
    "#%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import telebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! GPU is ready for use.\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! GPU is ready for use.\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot token is: 7990668627:AAEWVGv_F2Wxp2hzdpbGrvWdg_fW6pnrnTQ\n"
     ]
    }
   ],
   "source": [
    "# Load the .env file\n",
    "load_dotenv(\"token.env\")\n",
    "\n",
    "# Access the BOT_TOKEN variable\n",
    "BOT_TOKEN = os.getenv(\"BOT_TOKEN\")\n",
    "print(f\"Your bot token is: {BOT_TOKEN}\")\n",
    "bot = telebot.TeleBot(BOT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '<|system|>\\nYou are a friendly chatbot who always responds in the style of a teacher</s>\\n<|user|>\\nHello! How are you?</s>\\n<|assistant|>\\nI am fine, thank you. How about you?'}]\n"
     ]
    }
   ],
   "source": [
    "#testing pipeline\n",
    "''' messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a teacher\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Hello! How are you?\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['start','hello AI assistant'])\n",
    "def send_welcome(message):\n",
    "    bot.reply_to(message, \"Hi, how are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=[\"info\"])\n",
    "def send_info(message):\n",
    "  bot.reply_to(message, \"This is a simple Telegram bot implemented in Python.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(func=lambda msg: True)\n",
    "def echo_all(message):\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a friendly chatbot who always responds in the style of a teacher\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": message.text},\n",
    "    ]\n",
    "    #print(\"messages\",messages)\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    #print(\"prompt\",prompt)\n",
    "    outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "    print(\"outputs\",outputs)\n",
    "    reply=outputs[0][\"generated_text\"]\n",
    "    assistant_answer = reply[len(prompt):].strip()\n",
    "    bot.reply_to(message, assistant_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs [{'generated_text': '<|system|>\\nYou are a friendly chatbot who always responds in the style of a teacher</s>\\n<|user|>\\ntell me something about dogs</s>\\n<|assistant|>\\nDogs are one of the most beloved animals in the world. They are known for their loyalty, intelligence, and playfulness. Here are some interesting facts about dogs:\\n\\n1. Dogs are the second-most popular pets in the world, after cats.\\n\\n2. Dogs are the most popular breed in the US, with more than 9 million dogs owned by people.\\n\\n3. Dogs are the only animal that can understand human language.\\n\\n4. Dogs are considered to be emotional beings, just like humans.\\n\\n5. Dogs are great for mental health, as they provide companionship, stress relief, and emotional support.\\n\\n6. Dogs have a unique ability to recognize human emotions, such as joy, sadness, and anger.\\n\\n7. Dogs can sense when people are stressed or unhappy, and will often lick their owners to show empathy and comfort.\\n\\n8. Dogs can learn new commands and tricks through training, and can even perform tricks like catching balls, fetching, and walking on a leash.\\n\\n9. Dogs can communicate through body language, fa'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 16:10:28,914 (__init__.py:1121 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n",
      "2025-01-25 16:10:28,915 (__init__.py:1123 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n"
     ]
    }
   ],
   "source": [
    "bot.infinity_polling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
